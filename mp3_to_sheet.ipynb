{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5ff8cf23-80e2-493a-be72-c71d213f845e",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import mido\n",
        "import tensorflow as tf\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import numpy as np\n",
        "from utils.preprocess.quantize_note_timings import quantize_note_timings\n",
        "from utils.preprocess.normalize_velocities import normalize_velocities\n",
        "from utils.preprocess.filter_unnecessary_data import filter_unnecessary_data\n",
        "from utils.train.functions import split_train_validation_data, preprocess_data_for_training\n",
        "from music21 import *\n",
        "import musescore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c184ce27-d156-413c-95a0-9b0d40555b16",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def parse_midi_file(midi_file_path):\n",
        "    midi_data = mido.MidiFile(midi_file_path)\n",
        "    return midi_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e7f81a0b-988d-44e6-b6bd-4cbeaa342448",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def preprocess_midi_data(midi_data):\n",
        "    midi_data = quantize_note_timings(midi_data)\n",
        "    midi_data = normalize_velocities(midi_data)\n",
        "    midi_data = filter_unnecessary_data(midi_data)\n",
        "    return midi_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d8be268d-5a95-4e47-a3d9-dbd40a9f9db7",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def load_midi_files(file_directory):\n",
        "    midi_files = []\n",
        "    for root, dirs, files in os.walk(file_directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".mid\") or file.endswith(\".midi\"):\n",
        "                midi_files.append(os.path.join(root, file))\n",
        "    return midi_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8ad415bb-fcfd-4fa0-ac46-682a5f12f534",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def train_lstm_model(train_sequences, train_labels, validation_sequences, validation_labels, input_shape, num_classes):\n",
        "    print(\"Train sequences shape: \", train_sequences.shape)\n",
        "    print(\"Train labels shape: \", train_labels.shape)\n",
        "    print(\"Validation sequences shape: \", validation_sequences.shape)\n",
        "    print(\"Validation labels shape: \", validation_labels.shape)\n",
        "    print(\"Input shape: \", input_shape)\n",
        "    print(\"Number of classes: \", num_classes)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "        tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(units=128),\n",
        "        tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
        "    ])\n",
        "    print(model.summary())\n",
        "    print(\"Model input shape: \", model.input_shape)\n",
        "    print(\"Model output shape: \", model.output_shape)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(train_sequences, train_labels, epochs=20, validation_data=(validation_sequences, validation_labels))\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1df6ec5b-529f-43b2-8ccb-a9b672798d6f",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def train_machine_learning_model():\n",
        "    file_directory = \"./adl-piano-midi/Children\"\n",
        "    midi_files = load_midi_files(file_directory)\n",
        "    print(\"Loaded {} MIDI files\".format(len(midi_files)))\n",
        "    preprocessed_midi_data = [preprocess_midi_data(parse_midi_file(file)) for file in midi_files]\n",
        "    print(\"Preprocessed {} MIDI files\".format(len(preprocessed_midi_data)))\n",
        "    train_data, validation_data = split_train_validation_data(preprocessed_midi_data)\n",
        "    print(\"Split {} MIDI files into {} training files and {} validation files\".format(len(preprocessed_midi_data), len(train_data), len(validation_data)))\n",
        "    train_sequences, train_labels = preprocess_data_for_training(train_data)\n",
        "    print(\"Created {} training sequences and {} training labels\".format(len(train_sequences), len(train_labels)))\n",
        "    validation_sequences, validation_labels = preprocess_data_for_training(validation_data)\n",
        "    print(\"Created {} validation sequences and {} validation labels\".format(len(validation_sequences), len(validation_labels)))\n",
        "    input_shape = train_sequences.shape[1:]\n",
        "    num_classes = np.max(train_labels) + 1\n",
        "    model, history = train_lstm_model(train_sequences, train_labels, validation_sequences, validation_labels, input_shape, num_classes)\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "e9f9f6e1-6332-4ba5-9e7e-19db1c12e620",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def filter_midi_data(midi_data, model):\n",
        "    print(\"Midi data type: \", type(midi_data))\n",
        "    # Convert the MIDI data to numerical format suitable for the model\n",
        "    preprocessed_data = preprocess_midi_data(midi_data)\n",
        "    print(\"Preprocessed data type: \", type(preprocessed_data))\n",
        "\n",
        "    # Perform the prediction using the preprocessed data\n",
        "    predictions = model.predict(preprocessed_data)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "73342bf8-5947-466c-b29c-d4f130041161",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def convert_midi_to_music_representation(midi_data):\n",
        "    music_rep = converter.parse(midi_data)\n",
        "    return music_rep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f4d57155-0329-4d35-ba9e-90132ce763fd",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def generate_sheet_music(music_representation):\n",
        "    sheet_music = music_representation\n",
        "    return sheet_music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "415be847-39f0-4d0f-ace3-a26fc3ef9639",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def export_sheet_music(sheet_music, output_format, filename):\n",
        "    sheet_music.write(output_format, fp=filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5b20beb1-529c-4079-b088-c70eaccdb5d5",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MIDI file loaded and preprocessed\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()\n",
        "    midi_file_path = filedialog.askopenfilename()\n",
        "    midi_data = parse_midi_file(midi_file_path)\n",
        "    preprocess_midi_data(midi_data)\n",
        "    print(\"MIDI file loaded and preprocessed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "369c9583-3891-47c8-a34a-0ed80d558453",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 24 MIDI files\n",
            "Preprocessed 24 MIDI files\n",
            "Split 24 MIDI files into 19 training files and 5 validation files\n",
            "Created 41516 training sequences and 41516 training labels\n",
            "Created 9392 validation sequences and 9392 validation labels\n",
            "Train sequences shape:  (41516, 32, 2)\n",
            "Train labels shape:  (41516,)\n",
            "Validation sequences shape:  (9392, 32, 2)\n",
            "Validation labels shape:  (9392,)\n",
            "Input shape:  (32, 2)\n",
            "Number of classes:  104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-26 19:13:07.182411: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-26 19:13:07.186138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-26 19:13:07.188440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 32, 128)           67072     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 104)               13416     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,072\n",
            "Trainable params: 212,072\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model input shape:  (None, 32, 2)\n",
            "Model output shape:  (None, 104)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-26 19:13:07.534790: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-26 19:13:07.536717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-26 19:13:07.539797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-26 19:13:08.205302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-26 19:13:08.209261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-26 19:13:08.211947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-26 19:13:08.702991: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-26 19:13:08.707739: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-26 19:13:08.711008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-26 19:13:10.878773: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-26 19:13:10.882851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-26 19:13:10.886035: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-26 19:13:11.345186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-26 19:13:11.348021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-26 19:13:11.351261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1297/1298 [============================>.] - ETA: 0s - loss: 3.2837 - accuracy: 0.1140"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-26 19:14:04.641815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-26 19:14:04.646485: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-26 19:14:04.650176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-26 19:14:05.203412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-26 19:14:05.207593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-26 19:14:05.211201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1298/1298 [==============================] - 62s 43ms/step - loss: 3.2835 - accuracy: 0.1140 - val_loss: 3.3634 - val_accuracy: 0.0911\n",
            "Epoch 2/20\n",
            "1298/1298 [==============================] - 55s 42ms/step - loss: 2.9079 - accuracy: 0.1681 - val_loss: 3.3847 - val_accuracy: 0.0784\n",
            "Epoch 3/20\n",
            "1298/1298 [==============================] - 52s 40ms/step - loss: 2.7242 - accuracy: 0.2059 - val_loss: 3.5452 - val_accuracy: 0.0794\n",
            "Epoch 4/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 2.5905 - accuracy: 0.2348 - val_loss: 3.4972 - val_accuracy: 0.0800\n",
            "Epoch 5/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 2.4735 - accuracy: 0.2609 - val_loss: 3.5898 - val_accuracy: 0.0826\n",
            "Epoch 6/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 2.3713 - accuracy: 0.2850 - val_loss: 3.6238 - val_accuracy: 0.0763\n",
            "Epoch 7/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 2.2753 - accuracy: 0.3087 - val_loss: 3.6428 - val_accuracy: 0.0849\n",
            "Epoch 8/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 2.1873 - accuracy: 0.3377 - val_loss: 3.7921 - val_accuracy: 0.0752\n",
            "Epoch 9/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 2.1032 - accuracy: 0.3603 - val_loss: 3.7357 - val_accuracy: 0.0841\n",
            "Epoch 10/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 2.0333 - accuracy: 0.3783 - val_loss: 3.8872 - val_accuracy: 0.0743\n",
            "Epoch 11/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 1.9499 - accuracy: 0.4036 - val_loss: 3.9529 - val_accuracy: 0.0704\n",
            "Epoch 12/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 1.8804 - accuracy: 0.4229 - val_loss: 3.8936 - val_accuracy: 0.0935\n",
            "Epoch 13/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 1.8170 - accuracy: 0.4429 - val_loss: 3.8992 - val_accuracy: 0.0774\n",
            "Epoch 14/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 1.7582 - accuracy: 0.4598 - val_loss: 3.9202 - val_accuracy: 0.0871\n",
            "Epoch 15/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 1.6961 - accuracy: 0.4746 - val_loss: 4.2153 - val_accuracy: 0.0695\n",
            "Epoch 16/20\n",
            "1298/1298 [==============================] - 54s 42ms/step - loss: 1.6426 - accuracy: 0.4903 - val_loss: 4.0957 - val_accuracy: 0.0904\n",
            "Epoch 17/20\n",
            "1298/1298 [==============================] - 53s 41ms/step - loss: 1.5940 - accuracy: 0.5038 - val_loss: 4.3180 - val_accuracy: 0.0780\n",
            "Epoch 18/20\n",
            "1298/1298 [==============================] - 45s 35ms/step - loss: 1.5441 - accuracy: 0.5189 - val_loss: 4.3725 - val_accuracy: 0.0848\n",
            "Epoch 19/20\n",
            "1298/1298 [==============================] - 44s 34ms/step - loss: 1.4993 - accuracy: 0.5302 - val_loss: 4.4950 - val_accuracy: 0.0763\n",
            "Epoch 20/20\n",
            "1298/1298 [==============================] - 44s 34ms/step - loss: 1.4511 - accuracy: 0.5447 - val_loss: 4.5306 - val_accuracy: 0.0788\n",
            "Model trained\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'summary'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m train_machine_learning_model()\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel trained\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel summary: \u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39;49msummary())\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'summary'"
          ]
        }
      ],
      "source": [
        "model = train_machine_learning_model()\n",
        "print(\"Model trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 32, 128)           67072     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 104)               13416     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,072\n",
            "Trainable params: 212,072\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Sequential model show summary None\n"
          ]
        }
      ],
      "source": [
        "print(\"Sequential model show summary\", model[0].summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a0c85ef8-ab8b-46ae-8deb-d7eb66fa4b36",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Midi data type:  <class 'mido.midifiles.midifiles.MidiFile'>\n",
            "Preprocessed data type:  <class 'mido.midifiles.midifiles.MidiFile'>\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: <class 'mido.midifiles.midifiles.MidiFile'>, <class 'NoneType'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filter_midi_data(midi_data, model[\u001b[39m0\u001b[39;49m])\n",
            "Cell \u001b[0;32mIn[38], line 8\u001b[0m, in \u001b[0;36mfilter_midi_data\u001b[0;34m(midi_data, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPreprocessed data type: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m(preprocessed_data))\n\u001b[1;32m      7\u001b[0m \u001b[39m# Perform the prediction using the preprocessed data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(preprocessed_data)\n\u001b[1;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m predictions\n",
            "File \u001b[0;32m~/Documents/www/mp3-to-sheet/venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/Documents/www/mp3-to-sheet/venv/lib/python3.11/site-packages/keras/engine/data_adapter.py:1082\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1079\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1080\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1081\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1082\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1083\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1084\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1085\u001b[0m         )\n\u001b[1;32m   1086\u001b[0m     )\n\u001b[1;32m   1087\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1092\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'mido.midifiles.midifiles.MidiFile'>, <class 'NoneType'>"
          ]
        }
      ],
      "source": [
        "filter_midi_data(midi_data, model[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60689d09-7b4e-4206-9185-23735de0e055",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "music_representation = convert_midi_to_music_representation(midi_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1b437ae-784a-4b74-837f-a50ed727540d",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "sheet_music = generate_sheet_music(music_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7086bfb8-61f8-4934-afc7-130be416f9f4",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "output_file_path_XML = \"./resultXML/\" + os.path.splitext(os.path.basename(midi_file_path))[0] + \".xml\"\n",
        "output_file_path_PDF = \"./resultPDF/\" + os.path.splitext(os.path.basename(midi_file_path))[0] + \".pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a2e45a9-a8e4-4a8f-ae62-9bc4b324278f",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "export_sheet_music(sheet_music, \"musicxml\", output_file_path_XML)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "noteable": {
      "last_delta_id": "9a50b885-ab99-41e0-92c6-a7ad193c5bfc",
      "last_transaction_id": "5ec29572-6c7a-44d4-823d-944044ae6be5"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "9a09d67e-ed73-531f-90ae-3b1563d32216",
        "openai_ephemeral_user_id": "522f5357-3969-53cf-9d9a-0180fb5eee9a",
        "openai_subdivision1_iso_code": "ES-CT"
      }
    },
    "nteract": {
      "version": "noteable@2.9.0"
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
