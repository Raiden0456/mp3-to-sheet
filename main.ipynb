{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ff8cf23-80e2-493a-be72-c71d213f845e",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import mido\n",
        "import tensorflow as tf\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import numpy as np\n",
        "from utils.preprocess.quantize_note_timings import quantize_note_timings\n",
        "from utils.preprocess.normalize_velocities import normalize_velocities\n",
        "from utils.preprocess.filter_unnecessary_data import filter_unnecessary_data\n",
        "from utils.train.functions import split_train_validation_data, preprocess_data_for_training\n",
        "from utils.predict.functions import preprocess_data_for_prediction, postprocess_predictions_to_midi\n",
        "from utils.impure.functions import process_directory\n",
        "from music21 import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c184ce27-d156-413c-95a0-9b0d40555b16",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Read and parse MIDI file using mido\n",
        "def parse_midi_file(midi_file_path):\n",
        "    midi_data = mido.MidiFile(midi_file_path)\n",
        "    return midi_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f81a0b-988d-44e6-b6bd-4cbeaa342448",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Preprocess MIDI data before feeding it to the machine learning model\n",
        "def preprocess_midi_data(midi_data):\n",
        "    midi_data = quantize_note_timings(midi_data)\n",
        "    midi_data = normalize_velocities(midi_data)\n",
        "    midi_data = filter_unnecessary_data(midi_data)\n",
        "    return midi_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8be268d-5a95-4e47-a3d9-dbd40a9f9db7",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Load a list of MIDI files for training and validation\n",
        "def load_midi_files(file_directory):\n",
        "    midi_files = []\n",
        "    for root, dirs, files in os.walk(file_directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".mid\") or file.endswith(\".midi\"):\n",
        "                midi_files.append(os.path.join(root, file))\n",
        "\n",
        "    return midi_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad415bb-fcfd-4fa0-ac46-682a5f12f534",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def train_lstm_model(train_sequences, train_labels, validation_sequences, validation_labels, input_shape, num_classes):\n",
        "\n",
        "    print(\"Train sequences shape: \", train_sequences.shape)\n",
        "    print(\"Train labels shape: \", train_labels.shape)\n",
        "    print(\"Validation sequences shape: \", validation_sequences.shape)\n",
        "    print(\"Validation labels shape: \", validation_labels.shape)\n",
        "    print(\"Input shape: \", input_shape)\n",
        "    print(\"Number of classes: \", num_classes)\n",
        "\n",
        "    # Define the LSTM model architecture\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "        tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(units=128),\n",
        "        tf.keras.layers.Dense(units=1, activation='sigmoid')  # Change the number of units to 1 and the activation to 'sigmoid'\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Change the loss to 'binary_crossentropy'\n",
        "\n",
        "\n",
        "    # Fit the model to the data\n",
        "    history = model.fit(train_sequences, train_labels, epochs=20, validation_data=(validation_sequences, validation_labels))\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df6ec5b-529f-43b2-8ccb-a9b672798d6f",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def train_machine_learning_model():\n",
        "    # Load and preprocess my MIDI data\n",
        "    pure_file_directory = \"./adl-piano-midi/Pop/Karaoke\"\n",
        "    impure_file_directory = \"./adl-piano-midi-impure/Pop/Karaoke\"\n",
        "    \n",
        "    pure_midi_files = load_midi_files(pure_file_directory)\n",
        "    impure_midi_files = load_midi_files(impure_file_directory)\n",
        "    \n",
        "    print(\"Loaded {} pure MIDI files\".format(len(pure_midi_files)))\n",
        "    print(\"Loaded {} impure MIDI files\".format(len(impure_midi_files)))\n",
        "\n",
        "    preprocessed_pure_midi_data = [preprocess_midi_data(parse_midi_file(file)) for file in pure_midi_files]\n",
        "    preprocessed_impure_midi_data = [preprocess_midi_data(parse_midi_file(file)) for file in impure_midi_files]\n",
        "    \n",
        "    print(\"Preprocessed {} pure MIDI files\".format(len(preprocessed_pure_midi_data)))\n",
        "    print(\"Preprocessed {} impure MIDI files\".format(len(preprocessed_impure_midi_data)))\n",
        "\n",
        "    # Split the preprocessed MIDI data into training and validation sets\n",
        "    train_impure, validation_impure = split_train_validation_data(preprocessed_impure_midi_data)\n",
        "    train_pure, validation_pure = split_train_validation_data(preprocessed_pure_midi_data)\n",
        "    \n",
        "    print(\"Split {} MIDI files into {} training files and {} validation files\".format(len(preprocessed_impure_midi_data), len(train_impure), len(validation_impure)))\n",
        "\n",
        "    # Further preprocess the MIDI data to create input sequences and corresponding labels for training\n",
        "    train_sequences_impure, train_labels_impure = preprocess_data_for_training(train_impure, 0)\n",
        "    train_sequences_pure, train_labels_pure = preprocess_data_for_training(train_pure, 1)\n",
        "    train_sequences = np.concatenate((train_sequences_impure, train_sequences_pure))\n",
        "    train_labels = np.concatenate((train_labels_impure, train_labels_pure))\n",
        "\n",
        "    print(\"train_sequences shape: \", train_sequences.shape)\n",
        "    print(\"train_labels shape: \", train_labels.shape)\n",
        "\n",
        "\n",
        "    validation_sequences_impure, validation_labels_impure = preprocess_data_for_training(validation_impure, 0)\n",
        "    validation_sequences_pure, validation_labels_pure = preprocess_data_for_training(validation_pure, 1)\n",
        "    validation_sequences = np.concatenate((validation_sequences_impure, validation_sequences_pure))\n",
        "    validation_labels = np.concatenate((validation_labels_impure, validation_labels_pure))\n",
        "    \n",
        "    print(\"Created {} training sequences and {} validation sequences\".format(len(train_sequences), len(validation_sequences)))\n",
        "\n",
        "    # Determine input_shape and num_classes based on preprocessed data\n",
        "    input_shape = train_sequences.shape[1:] # Use the shape of the sequences for input_shape\n",
        "    num_classes = np.max(train_labels) + 1 # Determine the number of unique classes in train_labels\n",
        "\n",
        "    # Train the LSTM model\n",
        "    model, history = train_lstm_model(train_sequences, train_labels, validation_sequences, validation_labels, input_shape, num_classes)\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f9f6e1-6332-4ba5-9e7e-19db1c12e620",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def preprocess_data_for_prediction(midi_data, sequence_length=32):\n",
        "    midi_events = []\n",
        "    # Extract MIDI events from the MidiFile object\n",
        "    for track in midi_data.tracks:\n",
        "        for event in track:\n",
        "            if hasattr(event, 'note'):\n",
        "                midi_events.append([event.note, event.time])\n",
        "            else:\n",
        "                midi_events.append([0, event.time]) # Replace with appropriate handling\n",
        "\n",
        "    sequences = []\n",
        "    for i in range(len(midi_events) - sequence_length):\n",
        "        sequence = midi_events[i:i+sequence_length]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "    return np.array(sequences)\n",
        "\n",
        "def postprocess_predictions_to_midi(predictions, midi_data, threshold=0.000005, output_file_path=\"output.mid\"):\n",
        "    mid = mido.MidiFile()\n",
        "    track = mido.MidiTrack()\n",
        "    mid.tracks.append(track)\n",
        "\n",
        "    # Flatten the list of events\n",
        "    events = [event for track in midi_data.tracks for event in track if hasattr(event, 'note')]\n",
        "\n",
        "    # Ensure the number of events matches the number of predictions\n",
        "    events = events[:len(predictions)]\n",
        "\n",
        "    # Filter the events based on the predictions\n",
        "    filtered_events = [event for i, event in enumerate(events) if predictions[i] >= threshold]\n",
        "\n",
        "    # Append the filtered events to the track, along with a 'note_off' event for each 'note_on' event\n",
        "    for event in filtered_events:\n",
        "        if event.time >= 0:\n",
        "            track.append(event)\n",
        "            if event.type == 'note_on':\n",
        "                note_off = mido.Message('note_off', note=event.note, velocity=64, time=event.time)\n",
        "                track.append(note_off)\n",
        "\n",
        "    mid.save(output_file_path)\n",
        "    return mid\n",
        "\n",
        "\n",
        "def filter_midi_data(midi_data, model):\n",
        "    # Preprocess the MIDI data to get individual notes\n",
        "    input_notes = preprocess_data_for_prediction(midi_data)\n",
        "\n",
        "    print(\"Created {} input notes\".format(len(input_notes)))\n",
        "    print(\"Input notes shape: \", input_notes.shape)\n",
        "\n",
        "    # Predict whether each note is pure or impure\n",
        "    note_predictions = model.predict(input_notes)\n",
        "\n",
        "    print(\"Note predictions shape: \", note_predictions.shape)\n",
        "    print(\"Note predictions: \", note_predictions)\n",
        "\n",
        "    # Postprocess the note predictions to create a new MIDI file\n",
        "    clean_midi_data = postprocess_predictions_to_midi(note_predictions, midi_data)\n",
        "\n",
        "    return clean_midi_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73342bf8-5947-466c-b29c-d4f130041161",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "def convert_midi_to_musicxml(midi_data, midi_file_path, output_file_path):\n",
        "    # Save the MidiFile object to a file\n",
        "    midi_data.save(midi_file_path)\n",
        "\n",
        "    # Convert MIDI data to music representation using music21\n",
        "    music_rep = converter.parse(midi_file_path)\n",
        "\n",
        "    # Write the music representation to a MusicXML file\n",
        "    music_rep.write('musicxml', fp=output_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b20beb1-529c-4079-b088-c70eaccdb5d5",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model = train_machine_learning_model()\n",
        "    print(\"Model trained\")\n",
        "    #Make an impure version of the midi file directory and save it to adl-piano-midi-impure\n",
        "    # process_directory(\"./adl-piano-midi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0336ea5",
      "metadata": {},
      "outputs": [],
      "source": [
        "root = tk.Tk()\n",
        "root.withdraw()  # we don't want a full GUI, so keep the root window from appearing\n",
        "midi_file_path = filedialog.askopenfilename()  # show an \"Open\" dialog box and return the path to the selected file\n",
        "midi_data = parse_midi_file(midi_file_path)\n",
        "preprocess_midi_data(midi_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ae4877",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Filtering MIDI data...\")\n",
        "clean_midi = filter_midi_data(midi_data, model[0])\n",
        "print(\"Filtered MIDI data\")\n",
        "print(\"Clean MIDI data: \", clean_midi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cdb023d",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Converting MIDI to MusicXML...\")\n",
        "midi_file_path = \"./resultMIDI/\" + os.path.splitext(os.path.basename(midi_file_path))[0] + \".mid\"\n",
        "output_file_path_XML = \"./resultXML/\" + os.path.splitext(os.path.basename(midi_file_path))[0] + \".xml\"\n",
        "convert_midi_to_musicxml(clean_midi, midi_file_path, output_file_path_XML)\n",
        "print(\"Exported MusicXML to \", output_file_path_XML)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "noteable": {
      "last_delta_id": "9a50b885-ab99-41e0-92c6-a7ad193c5bfc",
      "last_transaction_id": "5ec29572-6c7a-44d4-823d-944044ae6be5"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "9a09d67e-ed73-531f-90ae-3b1563d32216",
        "openai_ephemeral_user_id": "522f5357-3969-53cf-9d9a-0180fb5eee9a",
        "openai_subdivision1_iso_code": "ES-CT"
      }
    },
    "nteract": {
      "version": "noteable@2.9.0"
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
